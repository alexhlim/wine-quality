
# Data Preprocessing and Model Tuning


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

%matplotlib inline
```


```python
# run settings (load dataset, colors, warnings)
# dataframe is called red_wine
%run -i red-wine-settings.py
```


```python
# get frequencies of wine qualities
print(red_wine.groupby(red_wine.quality).quality.count())
```

    quality
    3     10
    4     53
    5    681
    6    638
    7    199
    8     18
    Name: quality, dtype: int64


## Data Preprocessing

### Approach
There is a class imbalance issue. If we had roughly equal amounts of samples, it would be possible to perform multi-classification. 

Since the goal of our project is to detect good quality wine, let's transform this task into a binary classification task, where we will place wines in one of two bins based on quality: bad (3-6) and good (7-8). Now, the task becomes: are we able to distinguish between 'good' and 'bad' wines based on their features.


```python
# creating bins for 'good' and 'bad' quality wine
# Red Wine: 2 bins 'bad'(3-6) and 'good'(7-8)
bins_red = (2, 6, 8)

# 0: 'bad' wines, 1: 'good' wines
groups = [0, 1]
red_wine.quality = pd.cut(red_wine.quality, bins = bins_red, labels = groups)
```


```python
sns.countplot(x=red_wine.quality, color = OrRd[0]).set_title('Red Wine Quality Distribution (w/ Bins)')
```




    Text(0.5,1,'Red Wine Quality Distribution (w/ Bins)')




![png](images/2.images/2.output_6_1.png)


**Note**: There is still an class imbalance (more 'bad' wines than 'good' wines). This will affect what metric we will be using to judge our classifiers (we will cover shortly).


```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X = red_wine.drop('quality', axis=1)
y = red_wine['quality']

# 60% training, 40% testing
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=10)

# optimize performance
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

# convert back to df, add labels to columns
X_train = pd.DataFrame(X_train, columns = red_wine.drop('quality', axis =1).columns)
X_test = pd.DataFrame(X_test, columns = red_wine.drop('quality', axis =1).columns)
```

### Functions


```python
''' See number of true positives, true negatives, false positive, false negatives produced by classifier. '''
def plot_confusion_matrix(confusion_matrix):
    confusion_matrix_df = pd.DataFrame(confusion_matrix, index = [0,1], columns = [0,1])
    confusion_matrix_df.index.name = 'True Class'
    confusion_matrix_df.columns.name = 'Predicted Class'
    plt.figure(figsize = (5,5))
    # increase font size
    sns.set(font_scale = 1.4)
    sns.heatmap(confusion_matrix_df, 
            xticklabels = True,
            yticklabels = True,
            fmt = '.5g',
            cmap = 'OrRd',
            cbar = False,
            annot=True,)
    plt.title("Confusion Matrix", fontsize = 20)
    # set font back to normal
    sns.set(font_scale = 1)
    
'''
Train a classifier and plot it's precision (metric we will be using)
against a certain parameter (used for parameter tuning). 
'''
def train_vs_test_plot(clf_list, param, barplot = False):
    # store results
    results_train = []
    results_test = []
    for clf in clf_list:
        clf.fit(X_train, y_train)
        y_pred_train = clf.predict(X_train)
        y_pred_test = clf.predict(X_test)
        score_train = precision_score(y_train, y_pred_train)
        score_test = precision_score(y_test, y_pred_test)
        # store as tuple for convenient access
        results_train.append((getattr(clf, param), score_train))
        results_test.append((getattr(clf, param), score_test))
    
    # line plot
    if barplot is False:    
        plt.plot([tup[0] for tup in results_train], [tup[1] for tup in results_train], label='Train Set', color = light_red)
        plt.plot([tup[0] for tup in results_test], [tup[1] for tup in results_test],  label='Test Set', color = dark_red)
        plt.xlabel('{}'.format(param))
        plt.ylabel('Precision')
        plt.title('Train VS Test Scores')
        plt.legend(loc="lower right")
        plt.show()
    # bar plot
    else: 
        sns.set(font_scale = 1.2)
        sns.barplot([tup[0] for tup in results_train], [tup[1] for tup in results_train], label = 'Train', color = light_red)
        sns.barplot([tup[0] for tup in results_test], [tup[1] for tup in results_test], label = 'Test', color = dark_red)
        plt.suptitle('{} vs. Precision'.format(param))
        plt.legend(loc="upper left")
        plt.show()
        sns.set(font_scale = 1)

    max_train = max(results_train,key=lambda item:item[1])
    max_test = max(results_test,key=lambda item:item[1])

    # get max precision
    print('Highest Precision (Train): {} ({} = {})'.format(max_train[1], param, max_train[0]))
    print('Highest Precision (Test): {} ({} = {})'.format(max_test[1], param, max_test[0]))
    
'''See the decision boundary made by the classifier, useful for detecting overfitting.'''
def see_decision_boundaries(clf_list, param, figsize, nrows, ncols):
    plt.figure(figsize=figsize)
    index = 0
    for clf in clf_list:
        X = X_train[['alcohol', 'sulphates']]
        y = y_train.as_matrix(columns=None)
        clf.fit(X, y)
        index += 1
        plt.subplot(nrows, ncols, index)
        plot_decision_regions(X=X.values, 
                              y=y,
                              clf=clf,
                              colors = 'rosybrown,firebrick',
                              legend=2)
        # Update plot object with X/Y axis labels and Figure Title
        plt.xlabel(X.columns[0], size=14)
        plt.ylabel(X.columns[1], size=14)
        plt.title('{} = {}'.format(param, getattr(clf, param), fontsize=18))
    
    
```

## Classifiers

### Possible Metrics
- **accuracy**: total samples correctly classified out of the total number of samples
- **ROC-AUC**: compares the True Positive Rate (TPR) and False Positive Rate (FPR). Useful for distinguishing between classes. 
- **precision**: of the amount of samples the model predicted 'good', how many of those samples' true class is 'good'. <br>
$\frac{TP}{TP + FP}$
- **recall**: of the amount of samples the model predicted as 'good', how many of the 'good' samples did the model identify in the dataset. <br>
$\frac{TP}{TP + FN}$


We need to choose a metric that is unaffected by the class imbalance we encountered when making the 'good' and 'bad' wine bins. Accuracy and ROC-AUC take into account the number of samples in each corresponding class, making them not attractive metrics. Thus, we are left with precision and recall, as both of these metrics are unaffected by the number of 'bad' wine samples and instead focuses on 'good' wine samples. I will be using **precision** as a metric to judge our models because I believe that being able to pinpoint good quality wines will help me save money in the long term, instead of going through trial and error and tasting many different types of wine.


```python
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC 
from mlxtend.plotting import plot_decision_regions
```

### Random Forest
Ensemble learning method that consists of many decision trees. A certain amount of decision trees are built and each 'vote' for the corresponding class the new sample belongs to.



```python
# define baseline model
rf_baseline = RandomForestClassifier(random_state = 10, n_estimators = 300)
rf_baseline.fit(X_train, y_train)
y_pred = rf_baseline.predict(X_test)

print(classification_report(y_test, y_pred, digits = 3))
```

                  precision    recall  f1-score   support
    
               0      0.895     0.976     0.934       549
               1      0.683     0.308     0.424        91
    
       micro avg      0.881     0.881     0.881       640
       macro avg      0.789     0.642     0.679       640
    weighted avg      0.865     0.881     0.861       640
    



```python
y_pred = rf_baseline.predict(X_test)
plot_confusion_matrix(confusion_matrix(y_test, y_pred))
```


![png](images/2.images/2.output_15_0.png)



```python
# add noise
X_train_noise = pd.DataFrame(X_train).copy()
X_train_noise['NOISE'] = np.random.normal(0, 1, X_train_noise.shape[0])

# run random forest 100 times to get average feature importance
rf_noise = RandomForestClassifier(n_estimators = 300, n_jobs = 100, random_state = 10)
rf_noise.fit(X_train_noise, y_train)
# convert to df + rename cols
important_features = pd.DataFrame(rf_noise.feature_importances_,
                                     index = X_train_noise.columns,
                                     columns = ['importance']).sort_values('importance', ascending = False)
important_features = important_features.reset_index()
important_features.rename(columns = {'index':'feature'}, inplace = True) 

# assign color based on feature
c_palette = ['b' if ( feature == 'NOISE') else OrRd[color] for feature, color in zip(important_features.feature, important_features.index)]

f, ax = plt.subplots(figsize=(8, 6))
sns.set(font_scale = 1.2)
sns.barplot(x = 'importance', y = 'feature', data = important_features, palette = c_palette)
plt.suptitle('Important Features for Red Wine (w/ NOISE)', fontsize = 16)
sns.set(font_scale = 1)
```


![png](images/2.images/2.output_16_0.png)


The purpose of this was to figure out the important features (generated by the Random Forest) and see how they stacked up against each other. Then, I added some random noise to see which features would actually be significant and which would be not as much. Now, I want to train the model with the reduced features (all features higher than NOISE) and see if that were to produce a better model.


```python
# test model with reduced features
# find reduced_features
noise_index = important_features[important_features.feature == 'NOISE'].index[0] + 1
last_index = important_features[-1:].index[0] + 1
dropped_features = []
[dropped_features.append(important_features.iloc[index].feature) for index in range(noise_index, last_index)]

# train model with reduced features
X_train_reduced = X_train.drop(dropped_features, axis = 1)
X_test_reduced = X_test.drop(dropped_features, axis = 1)
rf_reduced = RandomForestClassifier(random_state = 10, n_estimators = 300)
rf_reduced.fit(X_train_reduced, y_train)
y_pred = rf_reduced.predict(X_test_reduced)
print(classification_report(y_test, y_pred, digits = 3))
```

                  precision    recall  f1-score   support
    
               0      0.896     0.971     0.932       549
               1      0.644     0.319     0.426        91
    
       micro avg      0.878     0.878     0.878       640
       macro avg      0.770     0.645     0.679       640
    weighted avg      0.860     0.878     0.860       640
    


Actually reducing features lowers precision and recall. It seems as if all features are contributing postively towards our scores, thus, I will be using all features for models going forward. 

#### Parameters to Tune:
- **max_depth**: depth size of a tree
- **n_estimators**: number of trees in the forest. Generally, the more trees the better accuracy, but slower computation.
- **max_features**: max number of features that the algorithm can assign to an individual tree.
- **min_samples_leaf**: The minimum number of samples in newly created leaves.


#### Max Depth


```python
max_depths = [int(x) for x in np.linspace(start = 2, stop = 100, num = 10)]
clf_list = []
for depth in max_depths:
    clf = RandomForestClassifier(max_depth = depth, n_jobs=-1, n_estimators = 300, random_state=12)
    clf_list.append(clf)

train_vs_test_plot(clf_list, 'max_depth')
```


![png](images/2.output_22_0.png)


    Highest Precision (Train): 1.0 (max_depth = 12)
    Highest Precision (Test): 0.6590909090909091 (max_depth = 12)


#### min_samples_split


```python
min_samples_splits = [int(x) for x in np.linspace(start = 2, stop = 40, num = 10)]
clf_list = []
for splits in min_samples_splits:
    clf = RandomForestClassifier(min_samples_split = splits, n_jobs=-1, n_estimators = 300, random_state=12)
    clf_list.append(clf)

train_vs_test_plot(clf_list, 'min_samples_split')
```


![png](images/2.output_24_0.png)


    Highest Precision (Train): 1.0 (min_samples_split = 2)
    Highest Precision (Test): 0.6842105263157895 (min_samples_split = 6)


#### n_estimators


```python
n_estimators = [int(x) for x in np.linspace(start = 1, stop = 500, num = 25)]
clf_list = []
for trees in n_estimators:
    clf = RandomForestClassifier(n_estimators = trees, n_jobs=-1, random_state=12)
    clf_list.append(clf)

train_vs_test_plot(clf_list, 'n_estimators')
```


![png](images/2.output_26_0.png)


    Highest Precision (Train): 1.0 (n_estimators = 21)
    Highest Precision (Test): 0.7317073170731707 (n_estimators = 104)


#### max_features


```python
max_features = ['auto', 'sqrt', 'log2', None]
clf_list = []
for max_feature in max_features:
    clf = RandomForestClassifier(max_features=max_feature, n_estimators=300, n_jobs=-1, random_state=12)
    clf_list.append(clf)
    
train_vs_test_plot(clf_list, 'max_features', barplot = True)
```


![png](images/2.output_28_0.png)


    Highest Precision (Train): 1.0 (max_features = auto)
    Highest Precision (Test): 0.6511627906976745 (max_features = auto)


#### min_samples_leaf


```python
min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 40, num = 10)]
clf_list = []
for samples in min_samples_leaf:
    clf = RandomForestClassifier(min_samples_leaf = samples, n_jobs=-1, n_estimators = 300, random_state=12)
    clf_list.append(clf)

train_vs_test_plot(clf_list, 'min_samples_leaf')
```


![png](images/2.output_30_0.png)


    Highest Precision (Train): 1.0 (min_samples_leaf = 1)
    Highest Precision (Test): 0.8 (min_samples_leaf = 40)



```python
# Trying hand-picked parameters
rf = RandomForestClassifier(max_depth = 12,
                            min_samples_split = 6,
                            n_estimators = 104,
                            max_features = 'auto',
                            min_samples_leaf = 30,
                            random_state = 10)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
print('-- Tuned Hyperparameter Random Forest --')
print(classification_report(y_test,y_pred,digits = 3))
```

    -- Tuned Hyperparameter Random Forest --
                  precision    recall  f1-score   support
    
               0      0.875     0.991     0.929       549
               1      0.722     0.143     0.239        91
    
       micro avg      0.870     0.870     0.870       640
       macro avg      0.798     0.567     0.584       640
    weighted avg      0.853     0.870     0.831       640
    


We were able to increase our precision for 1 ('good' wines) by about 10%! Although this does come with a cost-- the recall score is significantly lower.


```python
y_pred = rf.predict(X_test)
plot_confusion_matrix(confusion_matrix(y_test, y_pred))
```


![png](images/2.output_33_0.png)


### Logistic Regression
Supervised machine learning algorithm that returns a probability instead of a prediction.

#### Parameters to tune
- **penalty**: regularization term, either L1 (Lasso Regression) or L2 (Ridge Regression).
- **C**: inverse strength of regularization (ie. smaller values specify stronger regularization)
- **class_weights**: weights given to each class, which determines how much impact a sample has in moving determining the decision boundary. 


```python
# define baseline logistic regression model
logit_baseline = LogisticRegression(random_state = 10)
logit_baseline.fit(X_train, y_train)
y_pred = logit_baseline.predict(X_test)

print('-- Logistic Regression Baseline --')
print(classification_report(y_test, y_pred, digits = 3))
```

    -- Logistic Regression Baseline --
                  precision    recall  f1-score   support
    
               0      0.889     0.960     0.923       549
               1      0.532     0.275     0.362        91
    
       micro avg      0.863     0.863     0.863       640
       macro avg      0.710     0.617     0.643       640
    weighted avg      0.838     0.863     0.843       640
    



```python
# plot confusion matrix 
y_pred = logit_baseline.predict(X_test)
plot_confusion_matrix(confusion_matrix(y_test, y_pred))
```


![png](images/2.output_36_0.png)


#### C & penalty


```python
c_list = [0.001, 0.01, 0.1, 1, 10, 100]
clf_list = []
for c in c_list:
    clf = LogisticRegression(C = c, penalty = 'l1', random_state = 12)
    clf_list.append(clf)

print('-- {} Regularization --\n'.format('L1') ) 
train_vs_test_plot(clf_list, 'C', barplot = True)

clf_list = []
for c in c_list:
    clf = LogisticRegression(C = c, penalty = 'l2', random_state = 12)
    clf_list.append(clf)

print('\n-- {} Regularization --\n'.format('L2') )
train_vs_test_plot(clf_list, 'C', barplot = True)
```

    -- L1 Regularization --
    



![png](images/2.output_38_1.png)


    Highest Precision (Train): 0.6470588235294118 (C = 10)
    Highest Precision (Test): 0.7307692307692307 (C = 0.1)
    
    -- L2 Regularization --
    



![png](images/2.output_38_3.png)


    Highest Precision (Train): 0.6976744186046512 (C = 0.01)
    Highest Precision (Test): 0.7 (C = 0.01)



```python
c_list = [0.01, 0.1, 1, 10, 100]
clf_list = []
for c in c_list:
    clf = LogisticRegression(C = c, penalty = 'l1', random_state = 10)
    clf_list.append(clf)

print('-- Logistic Decision Boundaries w/ L1 Regualrization -- ')
see_decision_boundaries(clf_list = clf_list, 
                        param = 'C', 
                        figsize = (12,18), 
                        nrows = 3, 
                        ncols = 2)  



```

    -- Logistic Decision Boundaries w/ L1 Regualrization -- 



![png](images/2.output_39_1.png)



```python
c_list = [0.01, 0.1, 1, 10, 100]
clf_list = []
for c in c_list:
    clf = LogisticRegression(C = c, penalty = 'l2', random_state = 10)
    clf_list.append(clf)
print('-- Logistic Decision Boundaries w/ L2 Regualrization -- ')
see_decision_boundaries(clf_list = clf_list, 
                        param = 'C', 
                        figsize = (12,18), 
                        nrows = 3, 
                        ncols = 2)  
```

    -- Logistic Decision Boundaries w/ L2 Regualrization -- 



![png](images/2.output_40_1.png)


L2 regularization has a higher precision score than L1 by not much. C value that produced that best precision (for L2) shifted pretty far to the right, making the decision boundary look overly safe.   

#### class_weights


```python
results = []
class_weights = ['balanced', None, {0: 0.7, 1: 0.3}, {0: 0.3, 1: 0.7}]
print('-- Class Weights --')
for weight in class_weights:
    model = LogisticRegression(C = 0.01, penalty = 'l2', class_weight = weight, random_state = 12)
    model.fit(X_train, y_train)
    score = precision_score(y_test, model.predict(X_test))
    results.append(score)
    print('{}: {}'.format(weight, score))
    

```

    -- Class Weights --
    balanced: 0.3391304347826087
    None: 0.7
    {0: 0.7, 1: 0.3}: 0.0
    {0: 0.3, 1: 0.7}: 0.4407894736842105



```python
class_weights = ['balanced', None, {0: 0.7, 1: 0.3}, {0: 0.3, 1: 0.7}]
clf_list = []
for weight in class_weights:
    clf = LogisticRegression(C = 0.01, penalty = 'l2', class_weight = weight, random_state = 12)
    clf_list.append(clf)
see_decision_boundaries(clf_list = clf_list, 
                        param = 'class_weight', 
                        figsize = (12,18), 
                        nrows = 3, 
                        ncols = 2)  
```


![png](images/2.output_44_0.png)



```python
logit = LogisticRegression(C = 0.01, penalty = 'l2', class_weight = None, random_state = 10)
logit.fit(X_train, y_train)
y_pred = logit.predict(X_test)
print(classification_report(y_test,y_pred, digits = 3))
```

                  precision    recall  f1-score   support
    
               0      0.885     0.984     0.932       549
               1      0.700     0.231     0.347        91
    
       micro avg      0.877     0.877     0.877       640
       macro avg      0.793     0.607     0.639       640
    weighted avg      0.859     0.877     0.849       640
    


We were able to increase precision by 17%!


```python
y_pred = logit.predict(X_test)
plot_confusion_matrix(confusion_matrix(y_test, y_pred))
```


![png](images/2.output_47_0.png)


### Support Vector Machines
Supervised machine learning algorithm that combines the concepts of max margin and hinge loss to form a hyperplane to divide the classes. Can use many different functions to capture linear/non-linear relationships.

#### Parameters to Tune

- **kernel**: what function will be used by the algorithm (ie. linear, radial basis function, polynomial)
- **gamma**: kernel coefficient
- **C**: regularization strength


```python
svm_baseline = SVC(random_state = 10)
svm_baseline.fit(X_train,y_train)
print('-- SVM Baseline --')
print(classification_report(y_test, y_pred, digits = 3))
```

    -- SVM Baseline --
                  precision    recall  f1-score   support
    
               0      0.885     0.984     0.932       549
               1      0.700     0.231     0.347        91
    
       micro avg      0.877     0.877     0.877       640
       macro avg      0.793     0.607     0.639       640
    weighted avg      0.859     0.877     0.849       640
    



```python
y_pred = svm_baseline.predict(X_test)
plot_confusion_matrix(confusion_matrix(y_test, y_pred))
```


![png](images/2.output_50_0.png)


#### kernel


```python
kernels = ['linear', 'rbf', 'poly']
clf_list = []
for kernel in kernels:
    clf = SVC(kernel = kernel, random_state=12)
    clf_list.append(clf)

train_vs_test_plot(clf_list, 'kernel', barplot = True)
```


![png](images/2.output_52_0.png)


    Highest Precision (Train): 0.9090909090909091 (kernel = poly)
    Highest Precision (Test): 0.6486486486486487 (kernel = poly)



```python
kernels = ['linear', 'rbf', 'poly']
clf_list = []
for kernel in kernels:
    clf = SVC(kernel=kernel, random_state = 10)
    clf_list.append(clf)
    
see_decision_boundaries(clf_list = clf_list, 
                        param = 'kernel', 
                        figsize = (12,12), 
                        nrows = 2, 
                        ncols = 2)
```


![png](images/2.output_53_0.png)


Despite the 'poly' kernel having the highest score, I believe that the 'rbf' kernel best characterizes the shape of the decision boundary.

#### gamma


```python
gammas = [0.1, 1, 10, 100]
clf_list = []
for gamma in gammas:
    clf = SVC(gamma = gamma, kernel = 'rbf', random_state=12)
    clf_list.append(clf)

train_vs_test_plot(clf_list, 'gamma', barplot = True)
```


![png](images/2.output_56_0.png)


    Highest Precision (Train): 1.0 (gamma = 10)
    Highest Precision (Test): 0.7575757575757576 (gamma = 1)



```python
gammas = [0.1, 1, 10, 100]
clf_list = []
for gamma in gammas:
    clf = SVC(kernel='rbf', gamma = gamma, random_state = 10)
    clf_list.append(clf)
    
see_decision_boundaries(clf_list = clf_list, 
                        param = 'gamma', 
                        figsize = (12,12), 
                        nrows = 2, 
                        ncols = 2)
```


![png](images/2.output_57_0.png)


Performance is best when gamma = 1. When gamma > 1, it starts to overfit the dataset.

#### C


```python
c_list = [0.01, 0.1, 1, 10, 100]
clf_list = []
for c in c_list:
    clf = SVC(C = c, kernel = 'rbf', random_state=12)
    clf_list.append(clf)

train_vs_test_plot(clf_list, 'C', barplot = True)
```


![png](images/2.output_60_0.png)


    Highest Precision (Train): 0.9915254237288136 (C = 100)
    Highest Precision (Test): 0.6097560975609756 (C = 1)



```python
c_list = [0.01, 0.1, 1, 10, 100]
clf_list = []
for c in c_list:
    clf = SVC(kernel='rbf', C = c, random_state = 10)
    clf_list.append(clf)
    
see_decision_boundaries(clf_list = clf_list, 
                        param = 'C', 
                        figsize = (12,18), 
                        nrows = 3, 
                        ncols = 2)  
```


![png](images/2.output_61_0.png)


Performance is best when C = 1. Again, similarly to gamma, the model starts to overfit for values C > 1.


```python
svm = SVC(kernel = 'rbf',
          gamma = 1,
          C = 1,
          random_state = 10)
svm.fit(X_train,y_train)
y_pred = svm.predict(X_test)
print('-- SVM Tuned Hyperparameters --')
print(classification_report(y_test, y_pred, digits = 3))
```

    -- SVM Tuned Hyperparameters --
                  precision    recall  f1-score   support
    
               0      0.891     0.985     0.936       549
               1      0.758     0.275     0.403        91
    
       micro avg      0.884     0.884     0.884       640
       macro avg      0.824     0.630     0.670       640
    weighted avg      0.872     0.884     0.860       640
    


Increased precision by 14%!


```python
y_pred = svm.predict(X_test)
plot_confusion_matrix(confusion_matrix(y_test, y_pred))
```


![png](images/2.output_65_0.png)


# Next Section: [Model Selection and Deploying](3.red-wine-model-selection-and-deploying.ipynb)

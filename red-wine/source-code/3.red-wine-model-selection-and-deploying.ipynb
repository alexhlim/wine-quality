{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This class is designed to load, preprocess, and split data into train and test sets \n",
    "so that it is ready to be used by models.\n",
    "'''\n",
    "class Data:\n",
    "    def __init__(self, file, cols, target_col, preprocess_labels, preprocess_bins):\n",
    "        self.cols = list(cols)\n",
    "        self.target_col = target_col\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self._preprocess_data(file, cols, target_col, preprocess_labels, preprocess_bins)\n",
    "    \n",
    "    '''Load the data into a data frame, convert target into binary, and split the data into train and test sets'''\n",
    "    def _preprocess_data(self, file, cols, target_col, preprocess_labels, preprocess_bins):\n",
    "        # transform file to dataframe\n",
    "        file_df = self._load_data(file)\n",
    "        # rename variables: replace space with underscores (makes it easier to reference)\n",
    "        file_df.columns = [c.lower().replace(' ', '_') for c in file_df.columns]\n",
    "        # converting target variables to corresponding labels\n",
    "        file_df[target_col] = pd.cut(file_df[target_col], bins = preprocess_bins, labels = preprocess_labels)\n",
    "        \n",
    "        return self._split_data_train_test(X=file_df[cols], y=file_df[target_col])\n",
    "      \n",
    "    '''Load the csv with pandas.'''\n",
    "    def _load_data(self, file):\n",
    "        return pd.read_csv(file, sep=';')\n",
    "    \n",
    "    ''' Perform a 60% training and 40% testing split'''\n",
    "    def _split_data_train_test(self, X, y):\n",
    "        # 60% training, 40% testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=10)\n",
    "        # optimize performance of train set\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.fit_transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This class is designed to hold all of our models and be able to fit and predict with them. \n",
    "Also, it used to perform cross validation.\n",
    "'''\n",
    "class ModelContainer:\n",
    "    def __init__(self, models=[]):\n",
    "        self.models = models\n",
    "        self.best_model = None\n",
    "        self.predictions = None\n",
    "        self.mean_precision = {}\n",
    "    \n",
    "    '''Add a model to the container. '''    \n",
    "    def add_model(self, model):\n",
    "        self.models.append(model)\n",
    "        \n",
    "    '''Perform k-fold cross validation.'''   \n",
    "    def cross_validate(self, data, k):\n",
    "        for model in self.models:\n",
    "            score = np.mean(cross_val_score(model, data.X_test, data.y_test, scoring = 'precision', cv=k))\n",
    "            self.mean_precision[model] = score\n",
    "    \n",
    "    '''Selects model with highest preicision.'''    \n",
    "    def select_best_model(self):\n",
    "        self.best_model = max(self.mean_precision, key=self.mean_precision.get)\n",
    "    \n",
    "    '''Fits best model.'''\n",
    "    def best_model_fit(self, features, targets):\n",
    "        self.best_model.fit(features, targets)\n",
    "    \n",
    "    '''Scores features using best model.'''\n",
    "    def best_model_predict(self, features):\n",
    "        self.predictions = self.best_model.predict(features)\n",
    "    \n",
    "    '''Prints summary of models and the best model.'''\n",
    "    def print_results(self):\n",
    "        print('Model Summaries:')\n",
    "        for model in models.mean_precision:\n",
    "            print('\\n', model, '- Precision:', models.mean_precision[model])\n",
    "        print('\\nBest Model:\\n', models.best_model)\n",
    "        print('\\nPrecision of Best Model\\n', models.mean_precision[models.best_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection (using cross validation)\n",
    "\n",
    "We will now evaluate our models using 10-fold cross-validation. The model with the best cross-validation score will be the model we select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "file = 'winequality-red.csv'\n",
    "cols = ['fixed_acidity', 'volatile_acidity','citric_acid',\n",
    "        'residual_sugar','chlorides','free_sulfur_dioxide',\n",
    "        'total_sulfur_dioxide','density','ph',\n",
    "        'sulphates','alcohol']\n",
    "target_col = 'quality'\n",
    "preprocess_labels = [0,1]\n",
    "preprocess_bins = (2, 6, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data object\n",
    "data = Data(file, cols, target_col, preprocess_labels, preprocess_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add models to ModelContainer\n",
    "models = ModelContainer()\n",
    "models.add_model(RandomForestClassifier(max_depth = 12,\n",
    "                            min_samples_split = 6,\n",
    "                            n_estimators = 104,\n",
    "                            max_features = 'auto',\n",
    "                            min_samples_leaf = 30,\n",
    "                            random_state = 10))\n",
    "models.add_model(LogisticRegression(C = 0.01, \n",
    "                                    penalty = 'l2', \n",
    "                                    class_weight = None, \n",
    "                                    random_state = 10))\n",
    "models.add_model(SVC(kernel = 'rbf',\n",
    "                     gamma = 1,\n",
    "                     C = 1,\n",
    "                     random_state = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summaries:\n",
      "\n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=30, min_samples_split=6,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=104, n_jobs=None,\n",
      "            oob_score=False, random_state=10, verbose=0, warm_start=False) - Precision: 0.3\n",
      "\n",
      " LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=10, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False) - Precision: 0.589047619047619\n",
      "\n",
      " SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=10, shrinking=True,\n",
      "  tol=0.001, verbose=False) - Precision: 0.8333333333333333\n",
      "\n",
      "Best Model:\n",
      " SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=10, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      "Precision of Best Model\n",
      " 0.8333333333333333\n"
     ]
    }
   ],
   "source": [
    "# perform cross validation and show results\n",
    "models.cross_validate(data, k=10)\n",
    "models.select_best_model()\n",
    "models.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Support Vector Machines has the highest score! This comes as no suprise, as when we were doing our hyperparameter tuning, Support Vector Machines was able to define a boundary that most clearly incapsulates the relationship between 'good' and 'bad' wines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the final model with hand-selected parameters\n",
    "models.best_model_fit(data.X_train, data.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the classifier\n",
    "with open('fitted-svm.pkl', 'wb') as fid:\n",
    "    pickle.dump(models.best_model, fid)  \n",
    "    \n",
    "# load predictions to csv\n",
    "svm_final_predictions = pd.DataFrame(models.best_model_predict(data.X_test), columns=['predictions']).to_csv('red-wine-svm-final-prediction.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "We entered this project looking at specific characteristics that makeup a \"good\" wine and found the most prominent correlation to be alcohol content, making it the top factor to judge a bottle of wine. However, after analysis of other components such as sulphates, citric acid and pH level, we also found postive correlations with these features and the overall quality of a wine. At first glance, these features were overlooked due to their low amounts. The combination of these features working together really helps to enhance the quality of a wine.\n",
    "\n",
    "What appears internally in the finished product of a wine does not completely tell the whole story of a wine's quality. Other measures, often intangible, can also directly impact a bottle of wine's quality. These factors incldue the grape varietials' environemntal conditions and the equipment used in producing the wine.\n",
    "\n",
    "From our machine learning analysis, the best classifier to use is the Support Vector Machines since it is the best way to differentiate qualities through a non-linear decision boundary, leading to more accurate findings. This helps support my innitial feature exploration conclusion that \"good\" quality wines may possess very similar characteristics to \"bad\" quality wines. It would be interesting to collect more date to re-evaluate this dataset, especially with wines scoring in the 9s and 10s or below a score of 5. I believe this will definitely change the analysis. \n",
    "\n",
    "While what constitutes as a \"good\" quality wine can be precisely determined by tests like this, at the end of the day, the preferences over bottles of wine rely heavily on personal taste and past experiences. Our palettes' understanding and inclination towards a bottle of wine is created through going through all the archives of what we have previously tasted before. So a bottle of wine can taste like apple juice to one person and kiwis to another. Therefore, the factors outlined through this project serve as beginning standards of a good quality wine to help consumers make better economic decisions when it comes to wine. As for taste, I suggest to get drinking and discovering your favorite bottle!\n",
    "\n",
    "## Ways to improve\n",
    "1. Explore more machine learning algorithms that are able to detect non-linear relationships.\n",
    "2. Grid Search for optimal parameters.\n",
    "3. Gather more samples and see if we can evaluate on a different metric or possibly perform multi-class classification (if the classes are balanced). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
